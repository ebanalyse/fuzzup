{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Workflow"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "`fuzzup` offers a simple approach for clustering strings based on \n",
    "[Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) using\n",
    "[Fuzzy Matching](https://en.wikipedia.org/wiki/Fuzzy_matching_(computer-assisted_translation))\n",
    "in conjunction with [Hierarchical Clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering). In this section we will go through the nuts and bolts of `fuzzup` by applying it to a realistic use-case."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Use-case\n",
    "Say, we have used an algorithm to extract person names from a news article. The output from the algorithm is a list of strings and looks like this."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "strings = ['Donald Trump', 'Donald Trump', 'J. biden', 'joe biden', 'Biden', 'Bide', 'mark esper', 'Christopher c . miller', 'jim mattis', 'Nancy Pelosi', 'trumps', 'Trump', 'Donald', 'miller']\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "As you can see, the output is rather messy (partly due to the stochastic nature of the algorithm). Another reason for the output looking messy is, that for instance 'Joe Biden' has been mentioned a lot of times but in different ways, i.e. 'Joe Biden', 'J. Biden' and 'Biden'. \n",
    "\n",
    "We want to implement a meaningful structure of these strings entities by forming meaningful clusters from them, in which the entities are closely related. Also we want to this using Machine Learning, i.e. apply an algorithmic approach, that learns from the data and is able to form clusters without any human interaction what so ever.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Solution\n",
    "\n",
    "The solution `fuzzup` offers for this task consists of three steps\n",
    "\n",
    "1. Compute all of the mutual string distances (Levensteihn Distances/fuzzy ratios) between the strings\n",
    "2. Form clusters of strings based on the distances from (1)\n",
    "3. Rank the clusters by simply counting the number of nodes(strings) in each cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Compute String Distances\n",
    "\n",
    "First, we compute all of the mutual [fuzzy ratios]() for the strings.\n",
    "\n",
    "[Fuzzy ratios](https://en.wikipedia.org/wiki/Fuzzy_matching_(computer-assisted_translation)) are numbers between 0 and 100 are measures of similarity between strings. They are derived from the [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) - a string metric, that measures the distance between strings. \n",
    "\n",
    "In short the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. \n",
    "\n",
    "`fuzzup` has a function `compute_fuzzy_matrix` for this, that presents the output - the mutual fuzzy ratios - as a cross-tabular matrix with all ratios. We have chosen `partial_ratio` from the `fuzzywuzzy` package to do this. As the name suggests, it matches strings partially.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'compute_clusters' from 'fuzzup.gear' (/Users/lars.kjeldgaard/projects/fuzzup/venv/lib/python3.8/site-packages/fuzzup/gear.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91ee59a9c018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_fuzzy_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_and_rank_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfuzzy_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_fuzzy_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfuzzy_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'compute_clusters' from 'fuzzup.gear' (/Users/lars.kjeldgaard/projects/fuzzup/venv/lib/python3.8/site-packages/fuzzup/gear.py)"
     ]
    }
   ],
   "source": [
    "from fuzzup.gear import compute_fuzzy_matrix, form_clusters, form_clusters_and_rank\n",
    "from fuzzywuzzy import fuzz\n",
    "fuzzy_matrix = compute_fuzzy_matrix(strings, ratio = fuzz.partial_ratio)\n",
    "fuzzy_matrix"
   ]
  },
  {
   "source": [
    "As you see, the different string representations of e.g. Donald Trump and Joe Biden have high mutual fuzzy ratios. In comparision representations of different persons have relatively small fuzzy ratios.\n",
    "\n",
    "You can think of this matrix as a correlation matrix, that shows the correlation between strings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 2: Forming Clusters\n",
    "We can now use unsupervised learning to form clusters of the strings, if we treat the individual strings as observations with the mutual fuzzy ratios (in our `fuzzy_matrix`) as features.\n",
    "\n",
    "We will apply hierarchical clustering (see [ISLR p. 390-396](https://statlearning.com/ISLR%20Seventh%20Printing.pdf ) for a good description of hierarchical clustering).\n",
    "\n",
    "The clustering algorithm will form the clusters in order to minimize pairwise string distances intra-cluster. This is done by invoking the `form_clusters` function, i.e."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['donald trump', 'trump', 'trumps'],\n",
       " ['christopher c . miller', 'miller'],\n",
       " ['mark esper'],\n",
       " ['george floyds'],\n",
       " ['joe biden'],\n",
       " ['jim mattis'],\n",
       " ['nancy pelosi']]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "form_clusters(\n",
    "    fuzzy_matrix,\n",
    "    args_linkage = {'method': 'average',\n",
    "                    'metric': 'euclidean'},\n",
    ")"
   ]
  },
  {
   "source": [
    "Here we have applied the 'average' linkage function (popular choice), and we measure the pairwise distances between strings/clusters in an euclidean space spanned by the mutual fuzzy ratios.\n",
    "\n",
    "We see from the results, that different string representations of e.g. 'Donald Trump' have been clustered together.\n",
    "\n",
    "Depending on your use case, you can customize arguments for computing (1) the pairwise distrances 'args_pdist', (2) arguments for the linkage function 'args_linkage' (i.e. 'method' and 'metric'), (3) arguments for the hierarchical clustering algorithm 'args_cluster' and (4) the 'flatten_coef' that is a coefficient for computing a generic cutoff for deciding how many clusters to create."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Rank Clusters\n",
    "A simple/na√Øve approach for assigning weights to the different string clusters is to just count the number of nodes/strings in each cluster. `fuzzup` has a function for this: `form_clusters_and_rank`. `form_clusters_and_rank` performs steps 1 and 2 and ranks the clusters using this simple logic:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_clusters_and_rank(strings)"
   ]
  },
  {
   "source": [
    "As you see, the longest string from each cluster has been promoted to 'PROMOTED_STRING' for the given cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}